# Censoror
## Author
Anvesh Gupta

## Description

Censoror is a command-line tool that employs natural language processing and regular expressions to detect and redact confidential data in plain text files. It is capable of obscuring personal details such as names, dates, phone numbers, and addresses within the provided documents.

## Features

- Conceals identities, chronological data, contact numbers, and locations in text-based documents.
- Accepts input files designated through glob patterns.
- Offers insights into the redaction process.
- Enables the tailoring of redaction categories (identities, chronological data, contact details, locations).
- Directs the output of sanitized files to a chosen folder.

## Requirements

- Pipenv (for managing dependencies)
- Python 3.x

## Running and Installing instruction

1. Clone the repository:

   ```bash
   git clone https://github.com/your_username/Censoror.git
   ```
2. Navigate to the project directory:

   ```bash
   cd Censoror
   ```

2. Install dependencies using Pipenv:

   ```bash
   pipenv install
   ```

## Usage

### Main line

```bash
pipenv run python censoror.py --input './files/*.txt' --names --date --address --output 'docs/output' --stats stderr
```

### Options

- `--input`: Specify input files using glob patterns.
- `--output`: Specify the output directory for censored files.
- `--names`: Enable censorship of names.
- `--dates`: Enable censorship of dates.
- `--address`: Enable censorship of addresses.
- `--stats`: Choose statistics output destination (`stderr`, `stdout`, or a file path).

## Statistics Output

Statistics are presented according to the selected `--stats` option.

- Choosing `stderr` will result in statistics being outputted to the standard error stream.
- Selecting `stdout` means statistics will be displayed on the standard output stream.
- If a file path is provided, statistics will be written to the indicated file.

## Known Issues

- I have not figured out any bugs for now

## Assumptions

- The input files are in plain text format.
- The script assumes UTF-8 encoding for input files.
- The output directory is created if it does not exist.


## Function Description for - Fetch/Download, Parse/Extract, create, Populate/Insert, Status/Print

### `replace_with_blocks(text, entities)`

This function, `replace_with_blocks`, takes two arguments: `text`, which is a string, and `entities`, which is a list of substrings (presumably entities) to be replaced within the `text`. The function performs the following steps:
1. It first calls another function, `filter_out_4_digit_numbers`, with the `entities` list as its argument. This suggests that `filter_out_4_digit_numbers` is intended to process the `entities` list and return a modified list where entities that are 4-digit numbers might be filtered out, although without the implementation of `filter_out_4_digit_numbers`, the exact behavior on 4-digit numbers is not clear.
2. Then, for each entity in the filtered list (`ent`), it calculates a string (`full_block`) consisting of Unicode full block characters (`"\u2588"`). The length of this string of block characters matches the length of the entity it is replacing.
3. It replaces all occurrences of each entity in the original `text` with the corresponding string of block characters. This effectively obscures or censors the entities in the text by replacing them with a visual block of the same length.
4. Finally, the function returns the modified text where specified entities have been replaced with blocks.


### ` process_files(file_paths, output_dir)`

The function `process_files` takes two arguments: `file_paths`, a list of file paths to be processed, and `output_dir`, the directory path where the processed files will be saved. It performs the following steps:
1. Iterates through each file path in the `file_paths` list.
2. For each file, it attempts to:
   - Open and read the file's content.
   - Process the text content to detect specific information (the exact nature of this information isn't detailed but is done by a function called `detect_information`) and replace it with full block characters, effectively censoring or obscuring the identified information.
   - Generate a new file path for the censored output, appending ".censored" to the original file name and placing it in the specified `output_dir`.
   - If the `output_dir` doesn't exist, it creates the directory.
   - Write the modified (censored) text to the new output file.
3. The function prints messages to indicate the processing status of each file and any errors encountered during the process.

### `print_stats(count)`

The function `print_stats` takes a single argument `count`, which is expected to be a list or tuple containing four numerical values. These values represent counts of different types of information that have been censored: names, addresses, dates, and phone numbers, in that order. 
The function simply prints these counts to the console with descriptive labels for each type of censored information, providing a summary or statistics of the censorship performed. 

### ` __name__ == "__main__"`

In this block a CLI is set up using the `argparse` module to allow users to censor specific types of information (names, dates, phone numbers, addresses) in text files

### Additional Functions (in the ` __name__ == "__main__"` function):

1. It defines command-line arguments for the user to specify input file patterns (`--input`), an output directory (`--output`), and flags to indicate which types of information to censor (`--names`, `--dates`, `--phones`, `--address`). There is also an option (`--stats`) to choose where to output statistics (either `stdout` or `stderr`).
2. It checks if the `--input` argument is provided. If not, it prompts the user to provide input files using the `--input` flag.
3. It uses the provided glob patterns (from `--input`) to find matching text files within the current directory and stores their paths in a list.
4. It checks if any files were found with the specified patterns. If no files are found, it notifies the user.
5. It creates the specified output directory (`--output`) if it doesn't already exist.
6. It processes the found text files based on the specified censor flags (`--names`, `--dates`, `--phones`, `--address`). This involves reading each file, censoring the specified types of information, and saving the modified content to new files in the output directory.
7. The script requires at least one censor flag to be specified; otherwise, it prompts the user to specify at least one.

In short, this script provides a tool for automatically censoring specified types of sensitive information in text files, based on user-defined criteria, and saving the censored versions to a designated output directory.

## Test Cases Description -

The test case file is presumably designed to analyze text content and extract specific entities based on their types, such as names, dates, phone numbers, etc. The tests are written using the `unittest` framework, and `Mock` objects from the `unittest.mock` module are used to simulate the behavior of external dependencies (e.g., an NLP library) without requiring actual implementation details. Let's break down each function and explain what they do:

### `test_analyze_entities_name(self)`
- This test case checks if the `analyze_entities` function correctly identifies and extracts name entities from the provided text content. It uses `Mock` objects to simulate two entities labeled as "PERSON" (John Doe and Jane Smith) and checks if the function correctly returns these names as expected entities. The test passes if the function's output matches the list of expected entities (`["John Doe", "Jane Smith"]`).

### `test_empty_input(self)`
- This test case verifies the behavior of the `analyze_entities` function when it is given an empty string as input. The expected behavior is that the function should return an empty list, indicating that no entities were found in the text. The test passes if the function's output is an empty list.

### `test_no_entities(self)`
- This test case checks how the `analyze_entities` function handles input text that does not contain any relevant entities. For example, the sentence "The quick brown fox jumps over the lazy dog." does not include any names, dates, phone numbers, etc. The expected output is an empty list, and the test passes if the function returns an empty list, indicating no entities were found.

### `test_entities(self)`
- This test case is designed to evaluate the `analyze_entities` function's ability to identify and extract a mix of relevant and irrelevant entities from the provided text content. The text includes a date, an address, and a phone number. The test checks if the function correctly returns these entities while ignoring irrelevant information. The expected output is a list of the relevant entities (`["352-378-4990", "2024-03-15 at 2:30 PM.", "4000 SW 37th BLVD"]`), and the test passes if the actual output matches this expectation.

### `if __name__ == '__main__': unittest.main()`
- This line is the entry point for running the tests when the script is executed directly. `unittest.main()` provides a command-line interface for running the tests in the script. When this script is executed, it automatically runs all the test cases defined in the class `TestAnalyzeEntities`.



